<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>k8s on zoux的博客</title>
    <link>https://zoux86.github.io/tags/k8s/</link>
    <description>Recent content in k8s on zoux的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 17 Jul 2021 00:30:20 +0800</lastBuildDate><atom:link href="https://zoux86.github.io/tags/k8s/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>k8s中以不同的策略删除资源时发生了什么</title>
      <link>https://zoux86.github.io/post/2021-7-17-k8s%E4%B8%AD%E4%BB%A5%E4%B8%8D%E5%90%8C%E7%9A%84%E7%AD%96%E7%95%A5%E5%88%A0%E9%99%A4%E8%B5%84%E6%BA%90%E6%97%B6%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/</link>
      <pubDate>Sat, 17 Jul 2021 00:30:20 +0800</pubDate>
      
      <guid>https://zoux86.github.io/post/2021-7-17-k8s%E4%B8%AD%E4%BB%A5%E4%B8%8D%E5%90%8C%E7%9A%84%E7%AD%96%E7%95%A5%E5%88%A0%E9%99%A4%E8%B5%84%E6%BA%90%E6%97%B6%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/</guid>
      <description>接上篇gc源码分析，这篇主要总结以在不同的删除策略（孤儿，前台，后台）模式下，删除k8s资源发生了什么。 以下都是以 deployA , rsA, podA作为介绍。（这个可以类比为任何有这种依赖关系的资源） 1. 孤儿模式 孤儿模式删除deployA： deployA会被删除，rsA不会删除，但是rsA的Owner</description>
    </item>
    
    <item>
      <title>k8s gc controller源码分析</title>
      <link>https://zoux86.github.io/post/2021-7-17-k8s-gc%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</link>
      <pubDate>Sat, 17 Jul 2021 00:20:20 +0800</pubDate>
      
      <guid>https://zoux86.github.io/post/2021-7-17-k8s-gc%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</guid>
      <description>1. K8s 的垃圾回收策略 k8s目前支持三种回收策略： （1）前台级联删除（Foreground Cascading Deletion）：在这种删除策略中，所有者对象的删除将会持续到其所有从属对象都被删除为止。当所有者被删除时，会进入“正在删除”（deletion in progress）状态，此时： 对象仍然可以通</description>
    </item>
    
    <item>
      <title>k8s rs controller源码分析</title>
      <link>https://zoux86.github.io/post/2021-7-6-k8s-rs-controller-manager%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</link>
      <pubDate>Tue, 06 Jul 2021 00:30:20 +0800</pubDate>
      
      <guid>https://zoux86.github.io/post/2021-7-6-k8s-rs-controller-manager%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</guid>
      <description>1. startReplicaSetController 和deployController一样，kcm中定义了startReplicaSetController，startReplicaSetController和所有的控制器一样，先New一个对象，然后调用run函数。 这里可以看出来，rs控制器监听rs, 和pod的变化。 func startReplicaSetController(ctx ControllerContext) (http.Handler, bool,</description>
    </item>
    
    <item>
      <title>k8s deploy controller源码分析</title>
      <link>https://zoux86.github.io/post/2021-7-6-deployment-controller-manager%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</link>
      <pubDate>Tue, 06 Jul 2021 00:20:20 +0800</pubDate>
      
      <guid>https://zoux86.github.io/post/2021-7-6-deployment-controller-manager%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</guid>
      <description>1. deploy基础概念 root@k8s-master# kubectl get deploy nginx-deployment -oyaml apiVersion: apps/v1 kind: Deployment metadata: annotations: deployment.kubernetes.io/revision: &amp;#34;2&amp;#34; // 这个是版本号，说明这是第二个版本。 generation: 4 // 这里有个 generation labels: app: nginx name: nginx-deployment resourceVersion: &amp;#34;59522723&amp;#34; selfLink: /apis/apps/v1/namespaces/default/deployments/nginx-deployment uid: a6830e24-a479-452d-bbb2-3cb3cad82ebf spec: progressDeadlineSeconds: 600 replicas: 2 revisionHistoryLimit: 2 // 这个表明只保留2个版本。 selector: matchLabels: app: nginx strategy: rollingUpdate: maxSurge: 25% // 滚动更新的时候，不是一次就更新完了，而是一批一批的更新 maxUnavailable: 25% // 升级过程中最多有多少个 pod 处于无法提供服</description>
    </item>
    
    <item>
      <title>kubelet事件处理机制详解</title>
      <link>https://zoux86.github.io/post/2020-6-26-kubelet%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3/</link>
      <pubDate>Sat, 26 Jun 2021 00:32:20 +0800</pubDate>
      
      <guid>https://zoux86.github.io/post/2020-6-26-kubelet%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3/</guid>
      <description>本文从kubelet组件源码角度入手，分析kubelet中的事件处理机制 1. kubelet事件处理机制入口 // RunKubelet is responsible for setting up and running a kubelet. It is used in three different applications: // 1 Integration tests // 2 Kubelet binary // 3 Standalone &amp;#39;kubernetes&amp;#39; binary // Eventually, #2 will be replaced with instances of #3 // 第一步调用 makeEventRecorder，这里就表示 事件处理机制 产生了 func RunKubelet(kubeServer *options.KubeletServer, kubeDeps *kubelet.Dependencies, runOnce bool) error {</description>
    </item>
    
    <item>
      <title>k8s event介绍</title>
      <link>https://zoux86.github.io/post/2021-6-26-k8s-event%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Sat, 26 Jun 2021 00:30:20 +0800</pubDate>
      
      <guid>https://zoux86.github.io/post/2021-6-26-k8s-event%E4%BB%8B%E7%BB%8D/</guid>
      <description>k8s集群中，controller-manage、kube-proxy、kube-scheduler、kubelet等组件都会产生大量的event。这些event对查看集群对象状态或者监控告警等等都非常有用。本章写一下自己对k8s中event的理解。 1. event的定义 event定</description>
    </item>
    
    <item>
      <title>自定义metric server</title>
      <link>https://zoux86.github.io/post/2021-6-18-hpa-%E8%87%AA%E5%AE%9A%E4%B9%89metric-server/</link>
      <pubDate>Fri, 18 Jun 2021 00:31:20 +0800</pubDate>
      
      <guid>https://zoux86.github.io/post/2021-6-18-hpa-%E8%87%AA%E5%AE%9A%E4%B9%89metric-server/</guid>
      <description>本章重点： 如何基于 custom-metrics-apiserver 项目，打造自己的 metric server 1. custom-metrics-apiserver简介 项目地址： https://github.com/kubernetes-sigs/custom-metrics-apiserver/tree/master 自定义metric server，具体来说需要做以下几个事情： （1）实现 custom-metrics-apiserver 的 三个接口，如下： type CustomMetricsProvider interface { // 定义metric。 例如 pod_cpu_used_1m ListAllMetrics() []CustomMetricInfo // 如何根据 metric的信息，得到具体的值 GetMetricByName(name types.NamespacedName,</description>
    </item>
    
    <item>
      <title>hpa 源码分析</title>
      <link>https://zoux86.github.io/post/2021-6-18-hpa%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</link>
      <pubDate>Fri, 18 Jun 2021 00:30:20 +0800</pubDate>
      
      <guid>https://zoux86.github.io/post/2021-6-18-hpa%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</guid>
      <description>本章重点： 从源码角度分析hpa的计算逻辑 1. hpa介绍 1.1 hpa是什么 hpa指的是 Pod 水平自动扩缩，全名是Horizontal Pod Autoscaler简称HPA。它可以基于 CPU 利用率或其他指标自动扩缩 ReplicationController、Deployment 和 ReplicaSet 中的 Pod 数量。 用处： 用户</description>
    </item>
    
    <item>
      <title>k8s的基本组件</title>
      <link>https://zoux86.github.io/post/2019-12-15-k8s%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%84%E4%BB%B6/</link>
      <pubDate>Sun, 15 Dec 2019 01:31:20 +0800</pubDate>
      
      <guid>https://zoux86.github.io/post/2019-12-15-k8s%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%84%E4%BB%B6/</guid>
      <description>目录 （1）k8s简介 （2）k8s组件介绍 背景简介 Docker 项目和容器技术目前还是非常火热，但是Docker 技术栈，有自己的局限性，这是它的出发点决定的。那么在docker层之上，例如 容器编排？调度？容器云？集群管理？这些事情就需要另外一个项目来解决了。 在我最开始接触k8s的时候，我看到的</description>
    </item>
    
    <item>
      <title>k8s源码学习 - Scheduler笔记（1）</title>
      <link>https://zoux86.github.io/post/2019-11-24-k8s%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-scheduler%E7%AC%94%E8%AE%B01/</link>
      <pubDate>Sun, 21 Apr 2019 20:31:20 +0800</pubDate>
      
      <guid>https://zoux86.github.io/post/2019-11-24-k8s%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-scheduler%E7%AC%94%E8%AE%B01/</guid>
      <description>任务：找到scheduler的入口 k8s 代码目录结构 cmd：所有的二进制可执行文件入口代码，也就是各种命令的接口代码。 pkg：项目diamante主目录，cmd只是接口，这里是具体实现。cmd类似业务代码，pkg类似核心 寻找k8s入口函数 1 2 3 4 5 6 cmd/kube-schedule</description>
    </item>
    
    <item>
      <title>k8s源码学习 - Scheduler笔记（2）</title>
      <link>https://zoux86.github.io/post/2019-11-24-k8s%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-scheduler%E7%AC%94%E8%AE%B02/</link>
      <pubDate>Sun, 21 Apr 2019 20:31:20 +0800</pubDate>
      
      <guid>https://zoux86.github.io/post/2019-11-24-k8s%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-scheduler%E7%AC%94%E8%AE%B02/</guid>
      <description>接上文的工作，上文是找到了scheduler的入口。接下来看scheduler具体的执行。 1 2 3 4 5 cmd/kube-scheduler/scheduler.go:34main函数-&amp;gt; cmd/kube-scheduler/app/server.go:70NewSchedulerCommand-&amp;gt; cmd/kube-scheduler/app/server.go:117runCommand-&amp;gt; cmd/kube-scheduler/app/server.go:167Run-&amp;gt; pkg/scheduler/scheduler.go:276run-&amp;gt; 这是上文的工作 1 2 pkg/scheduler/scheduler.go:501scheduleOne-&amp;gt; pkg/scheduler/scheduler.go:291schedule-&amp;gt; 这里schedule只是一个街口，定义在 schedule/a</description>
    </item>
    
    <item>
      <title>k8s源码学习--代码结构</title>
      <link>https://zoux86.github.io/post/2019-11-24-k8s%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84/</link>
      <pubDate>Sun, 21 Apr 2019 20:31:20 +0800</pubDate>
      
      <guid>https://zoux86.github.io/post/2019-11-24-k8s%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84/</guid>
      <description>k8s版本：v1.13 k8s代码的结构 api: 输出接口文档用，基本是json源码 build：构建脚本 cmd：所有的二进制可执行文件入口代码，也就是各种命令的接口代码。 pkg：项目diamante主目录，cmd只是接口，这里是具体实现。cmd类似业务代码，pkg类似核心 plugin：插件</description>
    </item>
    
    <item>
      <title>k8s集群安装helm</title>
      <link>https://zoux86.github.io/post/2019-11-24-k8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85helm/</link>
      <pubDate>Mon, 01 Apr 2019 20:31:20 +0800</pubDate>
      
      <guid>https://zoux86.github.io/post/2019-11-24-k8s%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85helm/</guid>
      <description>helm介绍 helm的作用： Kubernetes一个包管理引擎 tiller的作用：功能和软件仓库一样，类似于/etc/yum.repos.d目录下的xxx.repo。 安装helm的目的是为了后面安装kube-batch 环境说明 环境：4台ubuntu16.04 1个master 3个n</description>
    </item>
    
    <item>
      <title>ubuntu搭建k8s机器</title>
      <link>https://zoux86.github.io/post/2019-11-24-%E6%90%AD%E5%BB%BAk8s%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Tue, 05 Mar 2019 20:31:20 +0800</pubDate>
      
      <guid>https://zoux86.github.io/post/2019-11-24-%E6%90%AD%E5%BB%BAk8s%E9%9B%86%E7%BE%A4/</guid>
      <description>本次在搭建k8s集群的过程中，遇到了很多问题，幸好最后终于成功。故将整个过程记录下来，希望对大家有所帮助。 环境说明 环境：4台ubuntu16.04 1个master 3个node k8s版本：V1.13.2 搭建说明 本教程采用kubeadm的方式安装，主要针对的是国内用户，因为安装k8s</description>
    </item>
    
    <item>
      <title>ubuntu机器之间免密登录</title>
      <link>https://zoux86.github.io/post/2019-11-24-ubuntu%E6%9C%BA%E5%99%A8%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/</link>
      <pubDate>Mon, 05 Nov 2018 20:31:20 +0800</pubDate>
      
      <guid>https://zoux86.github.io/post/2019-11-24-ubuntu%E6%9C%BA%E5%99%A8%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95/</guid>
      <description>在自己动手搭建k8s集群环境之前，经常遇到的一个问题就是，集群机器之间能互相免密登录。故在此记录整个搭建过程。 假设有俩台机器： 192.168.115.70 zx-1 master 192.168.115.66 zx-2 现在要修改成密码登录，并且这俩台机器免密登录。步骤如下： 修改 etc/hosts zx-1机器上 127.0.0.1 localhost zx-1 192.168.14.70 zx-1 192.168.14.66 zx-2 zx-2机器上 127.0.0.1 localhost zx-2 192.168.14.70 zx-1 192.168.14.66 zx-2 修改登录密码 修改root密</description>
    </item>
    
  </channel>
</rss>
